{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14e85dfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(adv='PGD', batchsize=128, dataset='binaryMnist', deletebatch=1, deletenum=0, isbatch=False, iterneumann=3, lam=0.0001, model='logistic', parllsize=128, remove_type=2, times=0)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from dataloder import *\n",
    "from argument import *\n",
    "from model import *\n",
    "from pretrain import *\n",
    "from utils import *\n",
    "from parllutils import *\n",
    "from functorch import vmap\n",
    "args = argument()\n",
    "device = 'cuda'\n",
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2d498d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(600, 1, 128)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delete_num = 600 # 删除600个点\n",
    "delete_batch = 1 # 从第1个点开始删\n",
    "pass_batch = args.parllsize \n",
    "delete_num, delete_batch, pass_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed46bf5",
   "metadata": {},
   "source": [
    "## Pre-processing\n",
    "### 1) load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "633bf385",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train labels: tensor([1, 1, 1,  ..., 1, 7, 1])\n",
      "total number of train data: 13007, test data: 2163\n"
     ]
    }
   ],
   "source": [
    "train_data, test_data, re_sequence = Load_Data(args, delete_num, shuffle=True)\n",
    "train_loader = make_loader(train_data, batch_size=args.batchsize)\n",
    "test_loader = make_loader(test_data, batch_size=args.batchsize)\n",
    "print(f\"total number of train data: {len(train_data[0])}, test data: {len(test_data[0])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "330b0e44",
   "metadata": {},
   "source": [
    "### 2) adversarially trained model (original model w*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac8ba8c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model information: \n",
      "LinearModel(\n",
      "  (fc): Linear(in_features=784, out_features=1, bias=False)\n",
      ")\n",
      "training type: PGD, epsilon: 0.25098, alpha: 0.03137, steps: 15\n",
      "training hyperparameters  lr: 0.010, epochs: 100 \n",
      "Epoch [1/100] training type PGD, learning rate : 0.0100 loss : 0.78296  adv_type : PGD model : logistic  times : 0\n",
      "Epoch [2/100] training type PGD, learning rate : 0.0100 loss : 0.59278  adv_type : PGD model : logistic  times : 0\n",
      "Epoch [3/100] training type PGD, learning rate : 0.0100 loss : 0.55324  adv_type : PGD model : logistic  times : 0\n",
      "Epoch [4/100] training type PGD, learning rate : 0.0100 loss : 0.52451  adv_type : PGD model : logistic  times : 0\n",
      "Epoch [5/100] training type PGD, learning rate : 0.0100 loss : 0.50273  adv_type : PGD model : logistic  times : 0\n",
      "Epoch [6/100] training type PGD, learning rate : 0.0100 loss : 0.48579  adv_type : PGD model : logistic  times : 0\n",
      "Epoch [7/100] training type PGD, learning rate : 0.0100 loss : 0.47229  adv_type : PGD model : logistic  times : 0\n",
      "Epoch [8/100] training type PGD, learning rate : 0.0100 loss : 0.46122  adv_type : PGD model : logistic  times : 0\n",
      "Epoch [9/100] training type PGD, learning rate : 0.0100 loss : 0.45217  adv_type : PGD model : logistic  times : 0\n",
      "Epoch [10/100] training type PGD, learning rate : 0.0100 loss : 0.44445  adv_type : PGD model : logistic  times : 0\n",
      "Epoch [11/100] training type PGD, learning rate : 0.0100 loss : 0.43786  adv_type : PGD model : logistic  times : 0\n",
      "Epoch [12/100] training type PGD, learning rate : 0.0100 loss : 0.43214  adv_type : PGD model : logistic  times : 0\n",
      "Epoch [13/100] training type PGD, learning rate : 0.0100 loss : 0.42715  adv_type : PGD model : logistic  times : 0\n",
      "Epoch [14/100] training type PGD, learning rate : 0.0100 loss : 0.42280  adv_type : PGD model : logistic  times : 0\n",
      "Epoch [15/100] training type PGD, learning rate : 0.0100 loss : 0.41889  adv_type : PGD model : logistic  times : 0\n",
      "Epoch [16/100] training type PGD, learning rate : 0.0100 loss : 0.41535  adv_type : PGD model : logistic  times : 0\n",
      "Epoch [17/100] training type PGD, learning rate : 0.0100 loss : 0.41218  adv_type : PGD model : logistic  times : 0\n",
      "Epoch [18/100] training type PGD, learning rate : 0.0100 loss : 0.40923  adv_type : PGD model : logistic  times : 0\n",
      "Epoch [19/100] training type PGD, learning rate : 0.0100 loss : 0.40652  adv_type : PGD model : logistic  times : 0\n",
      "Epoch [20/100] training type PGD, learning rate : 0.0100 loss : 0.40400  adv_type : PGD model : logistic  times : 0\n",
      "Epoch [21/100] training type PGD, learning rate : 0.0100 loss : 0.40165  adv_type : PGD model : logistic  times : 0\n",
      "Epoch [22/100] training type PGD, learning rate : 0.0100 loss : 0.39947  adv_type : PGD model : logistic  times : 0\n",
      "Epoch [23/100] training type PGD, learning rate : 0.0100 loss : 0.39738  adv_type : PGD model : logistic  times : 0\n",
      "Epoch [24/100] training type PGD, learning rate : 0.0100 loss : 0.39540  adv_type : PGD model : logistic  times : 0\n",
      "Epoch [25/100] training type PGD, learning rate : 0.0100 loss : 0.39357  adv_type : PGD model : logistic  times : 0\n",
      "Epoch [26/100] training type PGD, learning rate : 0.0100 loss : 0.39187  adv_type : PGD model : logistic  times : 0\n",
      "Epoch [27/100] training type PGD, learning rate : 0.0100 loss : 0.39033  adv_type : PGD model : logistic  times : 0\n",
      "Epoch [28/100] training type PGD, learning rate : 0.0100 loss : 0.38878  adv_type : PGD model : logistic  times : 0\n",
      "Epoch [29/100] training type PGD, learning rate : 0.0100 loss : 0.38735  adv_type : PGD model : logistic  times : 0\n",
      "Epoch [30/100] training type PGD, learning rate : 0.0100 loss : 0.38601  adv_type : PGD model : logistic  times : 0\n",
      "Epoch [31/100] training type PGD, learning rate : 0.0100 loss : 0.38468  adv_type : PGD model : logistic  times : 0\n",
      "Epoch [32/100] training type PGD, learning rate : 0.0100 loss : 0.38353  adv_type : PGD model : logistic  times : 0\n",
      "Epoch [33/100] training type PGD, learning rate : 0.0100 loss : 0.38241  adv_type : PGD model : logistic  times : 0\n",
      "Epoch [34/100] training type PGD, learning rate : 0.0100 loss : 0.38137  adv_type : PGD model : logistic  times : 0\n",
      "Epoch [35/100] training type PGD, learning rate : 0.0100 loss : 0.38035  adv_type : PGD model : logistic  times : 0\n",
      "Epoch [36/100] training type PGD, learning rate : 0.0100 loss : 0.37936  adv_type : PGD model : logistic  times : 0\n",
      "Epoch [37/100] training type PGD, learning rate : 0.0100 loss : 0.37842  adv_type : PGD model : logistic  times : 0\n",
      "Epoch [38/100] training type PGD, learning rate : 0.0100 loss : 0.37749  adv_type : PGD model : logistic  times : 0\n",
      "Epoch [39/100] training type PGD, learning rate : 0.0100 loss : 0.37664  adv_type : PGD model : logistic  times : 0\n",
      "Epoch [40/100] training type PGD, learning rate : 0.0100 loss : 0.37578  adv_type : PGD model : logistic  times : 0\n",
      "Epoch [41/100] training type PGD, learning rate : 0.0100 loss : 0.37496  adv_type : PGD model : logistic  times : 0\n",
      "Epoch [42/100] training type PGD, learning rate : 0.0100 loss : 0.37414  adv_type : PGD model : logistic  times : 0\n",
      "Epoch [43/100] training type PGD, learning rate : 0.0100 loss : 0.37339  adv_type : PGD model : logistic  times : 0\n",
      "Epoch [44/100] training type PGD, learning rate : 0.0100 loss : 0.37272  adv_type : PGD model : logistic  times : 0\n",
      "Epoch [45/100] training type PGD, learning rate : 0.0100 loss : 0.37202  adv_type : PGD model : logistic  times : 0\n",
      "Epoch [46/100] training type PGD, learning rate : 0.0100 loss : 0.37134  adv_type : PGD model : logistic  times : 0\n",
      "Epoch [47/100] training type PGD, learning rate : 0.0100 loss : 0.37070  adv_type : PGD model : logistic  times : 0\n",
      "Epoch [48/100] training type PGD, learning rate : 0.0100 loss : 0.37008  adv_type : PGD model : logistic  times : 0\n",
      "Epoch [49/100] training type PGD, learning rate : 0.0100 loss : 0.36946  adv_type : PGD model : logistic  times : 0\n",
      "Epoch [50/100] training type PGD, learning rate : 0.0100 loss : 0.36888  adv_type : PGD model : logistic  times : 0\n",
      "Epoch [51/100] training type PGD, learning rate : 0.0100 loss : 0.36825  adv_type : PGD model : logistic  times : 0\n",
      "Epoch [52/100] training type PGD, learning rate : 0.0100 loss : 0.36771  adv_type : PGD model : logistic  times : 0\n",
      "Epoch [53/100] training type PGD, learning rate : 0.0100 loss : 0.36717  adv_type : PGD model : logistic  times : 0\n",
      "Epoch [54/100] training type PGD, learning rate : 0.0100 loss : 0.36662  adv_type : PGD model : logistic  times : 0\n",
      "Epoch [55/100] training type PGD, learning rate : 0.0100 loss : 0.36605  adv_type : PGD model : logistic  times : 0\n",
      "Epoch [56/100] training type PGD, learning rate : 0.0100 loss : 0.36558  adv_type : PGD model : logistic  times : 0\n",
      "Epoch [57/100] training type PGD, learning rate : 0.0100 loss : 0.36512  adv_type : PGD model : logistic  times : 0\n",
      "Epoch [58/100] training type PGD, learning rate : 0.0100 loss : 0.36466  adv_type : PGD model : logistic  times : 0\n",
      "Epoch [59/100] training type PGD, learning rate : 0.0100 loss : 0.36424  adv_type : PGD model : logistic  times : 0\n",
      "Epoch [60/100] training type PGD, learning rate : 0.0100 loss : 0.36375  adv_type : PGD model : logistic  times : 0\n",
      "Epoch [61/100] training type PGD, learning rate : 0.0100 loss : 0.36336  adv_type : PGD model : logistic  times : 0\n",
      "Epoch [62/100] training type PGD, learning rate : 0.0100 loss : 0.36292  adv_type : PGD model : logistic  times : 0\n",
      "Epoch [63/100] training type PGD, learning rate : 0.0100 loss : 0.36253  adv_type : PGD model : logistic  times : 0\n",
      "Epoch [64/100] training type PGD, learning rate : 0.0100 loss : 0.36214  adv_type : PGD model : logistic  times : 0\n",
      "Epoch [65/100] training type PGD, learning rate : 0.0100 loss : 0.36178  adv_type : PGD model : logistic  times : 0\n",
      "Epoch [66/100] training type PGD, learning rate : 0.0100 loss : 0.36143  adv_type : PGD model : logistic  times : 0\n",
      "Epoch [67/100] training type PGD, learning rate : 0.0100 loss : 0.36107  adv_type : PGD model : logistic  times : 0\n",
      "Epoch [68/100] training type PGD, learning rate : 0.0100 loss : 0.36077  adv_type : PGD model : logistic  times : 0\n",
      "Epoch [69/100] training type PGD, learning rate : 0.0100 loss : 0.36051  adv_type : PGD model : logistic  times : 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [70/100] training type PGD, learning rate : 0.0100 loss : 0.36018  adv_type : PGD model : logistic  times : 0\n",
      "Epoch [71/100] training type PGD, learning rate : 0.0100 loss : 0.35991  adv_type : PGD model : logistic  times : 0\n",
      "Epoch [72/100] training type PGD, learning rate : 0.0100 loss : 0.35957  adv_type : PGD model : logistic  times : 0\n",
      "Epoch [73/100] training type PGD, learning rate : 0.0100 loss : 0.35931  adv_type : PGD model : logistic  times : 0\n",
      "Epoch [74/100] training type PGD, learning rate : 0.0100 loss : 0.35905  adv_type : PGD model : logistic  times : 0\n",
      "Epoch [75/100] training type PGD, learning rate : 0.0100 loss : 0.35878  adv_type : PGD model : logistic  times : 0\n",
      "Epoch [76/100] training type PGD, learning rate : 0.0100 loss : 0.35854  adv_type : PGD model : logistic  times : 0\n",
      "Epoch [77/100] training type PGD, learning rate : 0.0100 loss : 0.35825  adv_type : PGD model : logistic  times : 0\n",
      "Epoch [78/100] training type PGD, learning rate : 0.0100 loss : 0.35802  adv_type : PGD model : logistic  times : 0\n",
      "Epoch [79/100] training type PGD, learning rate : 0.0100 loss : 0.35778  adv_type : PGD model : logistic  times : 0\n",
      "Epoch [80/100] training type PGD, learning rate : 0.0100 loss : 0.35756  adv_type : PGD model : logistic  times : 0\n",
      "Epoch [81/100] training type PGD, learning rate : 0.0100 loss : 0.35726  adv_type : PGD model : logistic  times : 0\n",
      "Epoch [82/100] training type PGD, learning rate : 0.0100 loss : 0.35706  adv_type : PGD model : logistic  times : 0\n",
      "Epoch [83/100] training type PGD, learning rate : 0.0100 loss : 0.35681  adv_type : PGD model : logistic  times : 0\n",
      "Epoch [84/100] training type PGD, learning rate : 0.0100 loss : 0.35660  adv_type : PGD model : logistic  times : 0\n",
      "Epoch [85/100] training type PGD, learning rate : 0.0100 loss : 0.35638  adv_type : PGD model : logistic  times : 0\n",
      "Epoch [86/100] training type PGD, learning rate : 0.0100 loss : 0.35618  adv_type : PGD model : logistic  times : 0\n",
      "Epoch [87/100] training type PGD, learning rate : 0.0100 loss : 0.35592  adv_type : PGD model : logistic  times : 0\n",
      "Epoch [88/100] training type PGD, learning rate : 0.0100 loss : 0.35569  adv_type : PGD model : logistic  times : 0\n",
      "Epoch [89/100] training type PGD, learning rate : 0.0100 loss : 0.35551  adv_type : PGD model : logistic  times : 0\n",
      "Epoch [90/100] training type PGD, learning rate : 0.0100 loss : 0.35532  adv_type : PGD model : logistic  times : 0\n",
      "Epoch [91/100] training type PGD, learning rate : 0.0100 loss : 0.35510  adv_type : PGD model : logistic  times : 0\n",
      "Epoch [92/100] training type PGD, learning rate : 0.0100 loss : 0.35490  adv_type : PGD model : logistic  times : 0\n",
      "Epoch [93/100] training type PGD, learning rate : 0.0100 loss : 0.35467  adv_type : PGD model : logistic  times : 0\n",
      "Epoch [94/100] training type PGD, learning rate : 0.0100 loss : 0.35451  adv_type : PGD model : logistic  times : 0\n",
      "Epoch [95/100] training type PGD, learning rate : 0.0100 loss : 0.35431  adv_type : PGD model : logistic  times : 0\n",
      "Epoch [96/100] training type PGD, learning rate : 0.0100 loss : 0.35418  adv_type : PGD model : logistic  times : 0\n",
      "Epoch [97/100] training type PGD, learning rate : 0.0100 loss : 0.35397  adv_type : PGD model : logistic  times : 0\n",
      "Epoch [98/100] training type PGD, learning rate : 0.0100 loss : 0.35381  adv_type : PGD model : logistic  times : 0\n",
      "Epoch [99/100] training type PGD, learning rate : 0.0100 loss : 0.35365  adv_type : PGD model : logistic  times : 0\n",
      "Epoch [100/100] training type PGD, learning rate : 0.0100 loss : 0.35349  adv_type : PGD model : logistic  times : 0\n",
      "traning PGD model spending 219.47 seconds\n"
     ]
    }
   ],
   "source": [
    "# atk training (`torchattacks` package)\n",
    "model, training_time = train(train_loader, test_loader, args, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7236a54",
   "metadata": {},
   "source": [
    "### 3) pre-unlearning\n",
    "1) Calculate the related matrix \n",
    "2) Store the matrix to memory\n",
    "3) delete the matrix variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8661871",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([784, 1])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate matrix with MUter: parll_calculate_memory_matrix\n",
    "device = 'cuda'\n",
    "model = model.to(device)\n",
    "_, _, atk_info = training_param(args)\n",
    "\n",
    "atk = PGD(model, eps=atk_info[0], alpha=atk_info[1], steps=atk_info[2], lossfun=LossFunction(args.model), lam=args.lam)\n",
    "\n",
    "# 将所有参数 vectorization，即 flatten 成一个一维矩阵\n",
    "weight = vec_param(model.parameters()).detach()\n",
    "weight.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0f292d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算 ∂_𝜹𝜹 = ww^T 的逆，通过纽曼序列近似计算: I + (I-ww^T) + (I-ww^T)^2 + (I-ww^T)^3 + ……\n",
    "public_partial_dd = (weight.mm(weight.t())).detach() # w*wT\n",
    "public_partial_dd_inv = derive_inv(public_partial_dd, method='Neumann', iter=args.iterneumann)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de7c5719",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_hessian(weight, X, Y, args, batch_size=50000):\n",
    "    device = 'cuda'\n",
    "    weight = weight.to(device)\n",
    "    X = X.to(device)\n",
    "    Y = Y.to(device)\n",
    "    \n",
    "    # if args.model == 'logistic':\n",
    "    z = torch.sigmoid(Y * X.mm(weight)) # sigmoid(Y*Xw)\n",
    "    D = z * (1 - z) # sigmoid(Y*Xw) * (1-sigmoid(Y*Xw))\n",
    "    print(f\"z.shape: {z.shape}, D.shape: {D.shape}\")\n",
    "    H = None\n",
    "    num_batch = int(math.ceil(X.size(0) / batch_size)) # if batch_size == 50000, then use full batch\n",
    "    print(f\"(in func parllutils.batch_hessian) num_batch : {num_batch}, batch_size : {batch_size}\")\n",
    "    for i in range(num_batch):\n",
    "        lower = i * batch_size\n",
    "        upper = min((i+1) * batch_size, X.size(0))\n",
    "        print(f\"lower: {lower}, upper: {upper}\")\n",
    "        X_i = X[lower:upper]\n",
    "        if H is None:\n",
    "            H = X_i.t().mm(D[lower:upper] * X_i) # H += X^T D*X\n",
    "        else:\n",
    "            H += X_i.t().mm(D[lower:upper] * X_i)\n",
    "    return (H + args.lam * X.size(0) * torch.eye(X.size(1)).to(device)).detach()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b721bbb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process : [0/102]\n",
      "z.shape: torch.Size([128, 1]), D.shape: torch.Size([128, 1])\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "lower: 0, upper: 128\n",
      "process : [1/102]\n",
      "z.shape: torch.Size([128, 1]), D.shape: torch.Size([128, 1])\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "lower: 0, upper: 128\n",
      "process : [2/102]\n",
      "z.shape: torch.Size([128, 1]), D.shape: torch.Size([128, 1])\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "lower: 0, upper: 128\n",
      "process : [3/102]\n",
      "z.shape: torch.Size([128, 1]), D.shape: torch.Size([128, 1])\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "lower: 0, upper: 128\n",
      "process : [4/102]\n",
      "z.shape: torch.Size([128, 1]), D.shape: torch.Size([128, 1])\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "lower: 0, upper: 128\n",
      "process : [5/102]\n",
      "z.shape: torch.Size([128, 1]), D.shape: torch.Size([128, 1])\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "lower: 0, upper: 128\n",
      "process : [6/102]\n",
      "z.shape: torch.Size([128, 1]), D.shape: torch.Size([128, 1])\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "lower: 0, upper: 128\n",
      "process : [7/102]\n",
      "z.shape: torch.Size([128, 1]), D.shape: torch.Size([128, 1])\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "lower: 0, upper: 128\n",
      "process : [8/102]\n",
      "z.shape: torch.Size([128, 1]), D.shape: torch.Size([128, 1])\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "lower: 0, upper: 128\n",
      "process : [9/102]\n",
      "z.shape: torch.Size([128, 1]), D.shape: torch.Size([128, 1])\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "lower: 0, upper: 128\n",
      "process : [10/102]\n",
      "z.shape: torch.Size([128, 1]), D.shape: torch.Size([128, 1])\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "lower: 0, upper: 128\n",
      "process : [11/102]\n",
      "z.shape: torch.Size([128, 1]), D.shape: torch.Size([128, 1])\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "lower: 0, upper: 128\n",
      "process : [12/102]\n",
      "z.shape: torch.Size([128, 1]), D.shape: torch.Size([128, 1])\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "lower: 0, upper: 128\n",
      "process : [13/102]\n",
      "z.shape: torch.Size([128, 1]), D.shape: torch.Size([128, 1])\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "lower: 0, upper: 128\n",
      "process : [14/102]\n",
      "z.shape: torch.Size([128, 1]), D.shape: torch.Size([128, 1])\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "lower: 0, upper: 128\n",
      "process : [15/102]\n",
      "z.shape: torch.Size([128, 1]), D.shape: torch.Size([128, 1])\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "lower: 0, upper: 128\n",
      "process : [16/102]\n",
      "z.shape: torch.Size([128, 1]), D.shape: torch.Size([128, 1])\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "lower: 0, upper: 128\n",
      "process : [17/102]\n",
      "z.shape: torch.Size([128, 1]), D.shape: torch.Size([128, 1])\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "lower: 0, upper: 128\n",
      "process : [18/102]\n",
      "z.shape: torch.Size([128, 1]), D.shape: torch.Size([128, 1])\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "lower: 0, upper: 128\n",
      "process : [19/102]\n",
      "z.shape: torch.Size([128, 1]), D.shape: torch.Size([128, 1])\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "lower: 0, upper: 128\n",
      "process : [20/102]\n",
      "z.shape: torch.Size([128, 1]), D.shape: torch.Size([128, 1])\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "lower: 0, upper: 128\n",
      "process : [21/102]\n",
      "z.shape: torch.Size([128, 1]), D.shape: torch.Size([128, 1])\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "lower: 0, upper: 128\n",
      "process : [22/102]\n",
      "z.shape: torch.Size([128, 1]), D.shape: torch.Size([128, 1])\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "lower: 0, upper: 128\n",
      "process : [23/102]\n",
      "z.shape: torch.Size([128, 1]), D.shape: torch.Size([128, 1])\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "lower: 0, upper: 128\n",
      "process : [24/102]\n",
      "z.shape: torch.Size([128, 1]), D.shape: torch.Size([128, 1])\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "lower: 0, upper: 128\n",
      "process : [25/102]\n",
      "z.shape: torch.Size([128, 1]), D.shape: torch.Size([128, 1])\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "lower: 0, upper: 128\n",
      "process : [26/102]\n",
      "z.shape: torch.Size([128, 1]), D.shape: torch.Size([128, 1])\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "lower: 0, upper: 128\n",
      "process : [27/102]\n",
      "z.shape: torch.Size([128, 1]), D.shape: torch.Size([128, 1])\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "lower: 0, upper: 128\n",
      "process : [28/102]\n",
      "z.shape: torch.Size([128, 1]), D.shape: torch.Size([128, 1])\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "lower: 0, upper: 128\n",
      "process : [29/102]\n",
      "z.shape: torch.Size([128, 1]), D.shape: torch.Size([128, 1])\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "lower: 0, upper: 128\n",
      "process : [30/102]\n",
      "z.shape: torch.Size([128, 1]), D.shape: torch.Size([128, 1])\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "lower: 0, upper: 128\n",
      "process : [31/102]\n",
      "z.shape: torch.Size([128, 1]), D.shape: torch.Size([128, 1])\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "lower: 0, upper: 128\n",
      "process : [32/102]\n",
      "z.shape: torch.Size([128, 1]), D.shape: torch.Size([128, 1])\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "lower: 0, upper: 128\n",
      "process : [33/102]\n",
      "z.shape: torch.Size([128, 1]), D.shape: torch.Size([128, 1])\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "lower: 0, upper: 128\n",
      "process : [34/102]\n",
      "z.shape: torch.Size([128, 1]), D.shape: torch.Size([128, 1])\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "lower: 0, upper: 128\n",
      "process : [35/102]\n",
      "z.shape: torch.Size([128, 1]), D.shape: torch.Size([128, 1])\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "lower: 0, upper: 128\n",
      "process : [36/102]\n",
      "z.shape: torch.Size([128, 1]), D.shape: torch.Size([128, 1])\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "lower: 0, upper: 128\n",
      "process : [37/102]\n",
      "z.shape: torch.Size([128, 1]), D.shape: torch.Size([128, 1])\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "lower: 0, upper: 128\n",
      "process : [38/102]\n",
      "z.shape: torch.Size([128, 1]), D.shape: torch.Size([128, 1])\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "lower: 0, upper: 128\n",
      "process : [39/102]\n",
      "z.shape: torch.Size([128, 1]), D.shape: torch.Size([128, 1])\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "lower: 0, upper: 128\n",
      "process : [40/102]\n",
      "z.shape: torch.Size([128, 1]), D.shape: torch.Size([128, 1])\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "lower: 0, upper: 128\n",
      "process : [41/102]\n",
      "z.shape: torch.Size([128, 1]), D.shape: torch.Size([128, 1])\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "lower: 0, upper: 128\n",
      "process : [42/102]\n",
      "z.shape: torch.Size([128, 1]), D.shape: torch.Size([128, 1])\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "lower: 0, upper: 128\n",
      "process : [43/102]\n",
      "z.shape: torch.Size([128, 1]), D.shape: torch.Size([128, 1])\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "lower: 0, upper: 128\n",
      "process : [44/102]\n",
      "z.shape: torch.Size([128, 1]), D.shape: torch.Size([128, 1])\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "lower: 0, upper: 128\n",
      "process : [45/102]\n",
      "z.shape: torch.Size([128, 1]), D.shape: torch.Size([128, 1])\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "lower: 0, upper: 128\n",
      "process : [46/102]\n",
      "z.shape: torch.Size([128, 1]), D.shape: torch.Size([128, 1])\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "lower: 0, upper: 128\n",
      "process : [47/102]\n",
      "z.shape: torch.Size([128, 1]), D.shape: torch.Size([128, 1])\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "lower: 0, upper: 128\n",
      "process : [48/102]\n",
      "z.shape: torch.Size([128, 1]), D.shape: torch.Size([128, 1])\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "lower: 0, upper: 128\n",
      "process : [49/102]\n",
      "z.shape: torch.Size([128, 1]), D.shape: torch.Size([128, 1])\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "lower: 0, upper: 128\n",
      "process : [50/102]\n",
      "z.shape: torch.Size([128, 1]), D.shape: torch.Size([128, 1])\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "lower: 0, upper: 128\n",
      "process : [51/102]\n",
      "z.shape: torch.Size([128, 1]), D.shape: torch.Size([128, 1])\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "lower: 0, upper: 128\n",
      "process : [52/102]\n",
      "z.shape: torch.Size([128, 1]), D.shape: torch.Size([128, 1])\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "lower: 0, upper: 128\n",
      "process : [53/102]\n",
      "z.shape: torch.Size([128, 1]), D.shape: torch.Size([128, 1])\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "lower: 0, upper: 128\n",
      "process : [54/102]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z.shape: torch.Size([128, 1]), D.shape: torch.Size([128, 1])\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "lower: 0, upper: 128\n",
      "process : [55/102]\n",
      "z.shape: torch.Size([128, 1]), D.shape: torch.Size([128, 1])\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "lower: 0, upper: 128\n",
      "process : [56/102]\n",
      "z.shape: torch.Size([128, 1]), D.shape: torch.Size([128, 1])\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "lower: 0, upper: 128\n",
      "process : [57/102]\n",
      "z.shape: torch.Size([128, 1]), D.shape: torch.Size([128, 1])\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "lower: 0, upper: 128\n",
      "process : [58/102]\n",
      "z.shape: torch.Size([128, 1]), D.shape: torch.Size([128, 1])\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "lower: 0, upper: 128\n",
      "process : [59/102]\n",
      "z.shape: torch.Size([128, 1]), D.shape: torch.Size([128, 1])\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "lower: 0, upper: 128\n",
      "process : [60/102]\n",
      "z.shape: torch.Size([128, 1]), D.shape: torch.Size([128, 1])\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "lower: 0, upper: 128\n",
      "process : [61/102]\n",
      "z.shape: torch.Size([128, 1]), D.shape: torch.Size([128, 1])\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "lower: 0, upper: 128\n",
      "process : [62/102]\n",
      "z.shape: torch.Size([128, 1]), D.shape: torch.Size([128, 1])\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "lower: 0, upper: 128\n",
      "process : [63/102]\n",
      "z.shape: torch.Size([128, 1]), D.shape: torch.Size([128, 1])\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "lower: 0, upper: 128\n",
      "process : [64/102]\n",
      "z.shape: torch.Size([128, 1]), D.shape: torch.Size([128, 1])\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "lower: 0, upper: 128\n",
      "process : [65/102]\n",
      "z.shape: torch.Size([128, 1]), D.shape: torch.Size([128, 1])\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "lower: 0, upper: 128\n",
      "process : [66/102]\n",
      "z.shape: torch.Size([128, 1]), D.shape: torch.Size([128, 1])\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "lower: 0, upper: 128\n",
      "process : [67/102]\n",
      "z.shape: torch.Size([128, 1]), D.shape: torch.Size([128, 1])\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "lower: 0, upper: 128\n",
      "process : [68/102]\n",
      "z.shape: torch.Size([128, 1]), D.shape: torch.Size([128, 1])\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "lower: 0, upper: 128\n",
      "process : [69/102]\n",
      "z.shape: torch.Size([128, 1]), D.shape: torch.Size([128, 1])\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "lower: 0, upper: 128\n",
      "process : [70/102]\n",
      "z.shape: torch.Size([128, 1]), D.shape: torch.Size([128, 1])\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "lower: 0, upper: 128\n",
      "process : [71/102]\n",
      "z.shape: torch.Size([128, 1]), D.shape: torch.Size([128, 1])\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "lower: 0, upper: 128\n",
      "process : [72/102]\n",
      "z.shape: torch.Size([128, 1]), D.shape: torch.Size([128, 1])\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "lower: 0, upper: 128\n",
      "process : [73/102]\n",
      "z.shape: torch.Size([128, 1]), D.shape: torch.Size([128, 1])\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "lower: 0, upper: 128\n",
      "process : [74/102]\n",
      "z.shape: torch.Size([128, 1]), D.shape: torch.Size([128, 1])\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "lower: 0, upper: 128\n",
      "process : [75/102]\n",
      "z.shape: torch.Size([128, 1]), D.shape: torch.Size([128, 1])\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "lower: 0, upper: 128\n",
      "process : [76/102]\n",
      "z.shape: torch.Size([128, 1]), D.shape: torch.Size([128, 1])\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "lower: 0, upper: 128\n",
      "process : [77/102]\n",
      "z.shape: torch.Size([128, 1]), D.shape: torch.Size([128, 1])\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "lower: 0, upper: 128\n",
      "process : [78/102]\n",
      "z.shape: torch.Size([128, 1]), D.shape: torch.Size([128, 1])\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "lower: 0, upper: 128\n",
      "process : [79/102]\n",
      "z.shape: torch.Size([128, 1]), D.shape: torch.Size([128, 1])\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "lower: 0, upper: 128\n",
      "process : [80/102]\n",
      "z.shape: torch.Size([128, 1]), D.shape: torch.Size([128, 1])\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "lower: 0, upper: 128\n",
      "process : [81/102]\n",
      "z.shape: torch.Size([128, 1]), D.shape: torch.Size([128, 1])\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "lower: 0, upper: 128\n",
      "process : [82/102]\n",
      "z.shape: torch.Size([128, 1]), D.shape: torch.Size([128, 1])\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "lower: 0, upper: 128\n",
      "process : [83/102]\n",
      "z.shape: torch.Size([128, 1]), D.shape: torch.Size([128, 1])\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "lower: 0, upper: 128\n",
      "process : [84/102]\n",
      "z.shape: torch.Size([128, 1]), D.shape: torch.Size([128, 1])\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "lower: 0, upper: 128\n",
      "process : [85/102]\n",
      "z.shape: torch.Size([128, 1]), D.shape: torch.Size([128, 1])\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "lower: 0, upper: 128\n",
      "process : [86/102]\n",
      "z.shape: torch.Size([128, 1]), D.shape: torch.Size([128, 1])\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "lower: 0, upper: 128\n",
      "process : [87/102]\n",
      "z.shape: torch.Size([128, 1]), D.shape: torch.Size([128, 1])\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "lower: 0, upper: 128\n",
      "process : [88/102]\n",
      "z.shape: torch.Size([128, 1]), D.shape: torch.Size([128, 1])\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "lower: 0, upper: 128\n",
      "process : [89/102]\n",
      "z.shape: torch.Size([128, 1]), D.shape: torch.Size([128, 1])\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "lower: 0, upper: 128\n",
      "process : [90/102]\n",
      "z.shape: torch.Size([128, 1]), D.shape: torch.Size([128, 1])\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "lower: 0, upper: 128\n",
      "process : [91/102]\n",
      "z.shape: torch.Size([128, 1]), D.shape: torch.Size([128, 1])\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "lower: 0, upper: 128\n",
      "process : [92/102]\n",
      "z.shape: torch.Size([128, 1]), D.shape: torch.Size([128, 1])\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "lower: 0, upper: 128\n",
      "process : [93/102]\n",
      "z.shape: torch.Size([128, 1]), D.shape: torch.Size([128, 1])\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "lower: 0, upper: 128\n",
      "process : [94/102]\n",
      "z.shape: torch.Size([128, 1]), D.shape: torch.Size([128, 1])\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "lower: 0, upper: 128\n",
      "process : [95/102]\n",
      "z.shape: torch.Size([128, 1]), D.shape: torch.Size([128, 1])\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "lower: 0, upper: 128\n",
      "process : [96/102]\n",
      "z.shape: torch.Size([128, 1]), D.shape: torch.Size([128, 1])\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "lower: 0, upper: 128\n",
      "process : [97/102]\n",
      "z.shape: torch.Size([128, 1]), D.shape: torch.Size([128, 1])\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "lower: 0, upper: 128\n",
      "process : [98/102]\n",
      "z.shape: torch.Size([128, 1]), D.shape: torch.Size([128, 1])\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "lower: 0, upper: 128\n",
      "process : [99/102]\n",
      "z.shape: torch.Size([128, 1]), D.shape: torch.Size([128, 1])\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "lower: 0, upper: 128\n",
      "process : [100/102]\n",
      "z.shape: torch.Size([128, 1]), D.shape: torch.Size([128, 1])\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "lower: 0, upper: 128\n",
      "process : [101/102]\n",
      "z.shape: torch.Size([79, 1]), D.shape: torch.Size([79, 1])\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "lower: 0, upper: 79\n"
     ]
    }
   ],
   "source": [
    "# # 计算n个点的 total Hessian\n",
    "# pass_loader = make_loader(train_data, batch_size=pass_batch)\n",
    "# lenth = len(pass_loader)\n",
    "\n",
    "# feature = get_featrue(args) # featrue_dict[‘binaryMnist’]=784\n",
    "# matrix = torch.zeros((feature, feature)).to(device) # 784*784\n",
    "# # if method == 'MUter':\n",
    "# parll_partial = batch_indirect_hessian(args) # func\n",
    "# for index, (image, label) in enumerate(pass_loader):\n",
    "#     print('process : [{}/{}]'.format(index, lenth))\n",
    "#     image = image.to(device)\n",
    "#     label = label.to(device)\n",
    "#     image = atk(image, label).to(device)\n",
    "#     # direct Hessian\n",
    "#     matrix += batch_hessian(weight, image.view(image.shape[0], feature), label, args)\n",
    "#     # indirect Hessian: 用到之前计算的 public_partial_dd_inv\n",
    "#     matrix -= parll_partial(image.view(image.shape[0], feature, 1), label, weight, public_partial_dd_inv).sum(dim=0).detach()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd933213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102\n",
      "weight's shape: torch.Size([784, 1])\n",
      "process : [0/102]\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "process : [1/102]\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "process : [2/102]\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "process : [3/102]\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "process : [4/102]\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "process : [5/102]\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "process : [6/102]\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "process : [7/102]\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "process : [8/102]\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "process : [9/102]\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "process : [10/102]\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "process : [11/102]\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "process : [12/102]\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "process : [13/102]\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "process : [14/102]\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "process : [15/102]\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "process : [16/102]\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "process : [17/102]\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "process : [18/102]\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "process : [19/102]\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "process : [20/102]\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "process : [21/102]\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "process : [22/102]\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "process : [23/102]\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "process : [24/102]\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "process : [25/102]\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "process : [26/102]\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "process : [27/102]\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "process : [28/102]\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "process : [29/102]\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "process : [30/102]\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "process : [31/102]\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "process : [32/102]\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "process : [33/102]\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "process : [34/102]\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "process : [35/102]\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "process : [36/102]\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "process : [37/102]\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "process : [38/102]\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "process : [39/102]\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "process : [40/102]\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "process : [41/102]\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "process : [42/102]\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "process : [43/102]\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "process : [44/102]\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "process : [45/102]\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "process : [46/102]\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "process : [47/102]\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "process : [48/102]\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "process : [49/102]\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "process : [50/102]\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "process : [51/102]\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "process : [52/102]\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "process : [53/102]\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "process : [54/102]\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "process : [55/102]\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "process : [56/102]\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "process : [57/102]\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "process : [58/102]\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "process : [59/102]\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "process : [60/102]\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "process : [61/102]\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "process : [62/102]\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "process : [63/102]\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "process : [64/102]\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "process : [65/102]\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "process : [66/102]\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "process : [67/102]\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "process : [68/102]\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "process : [69/102]\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "process : [70/102]\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "process : [71/102]\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "process : [72/102]\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "process : [73/102]\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "process : [74/102]\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "process : [75/102]\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "process : [76/102]\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "process : [77/102]\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "process : [78/102]\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "process : [79/102]\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "process : [80/102]\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "process : [81/102]\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "process : [82/102]\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "process : [83/102]\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "process : [84/102]\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "process : [85/102]\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "process : [86/102]\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "process : [87/102]\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "process : [88/102]\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "process : [89/102]\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "process : [90/102]\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "process : [91/102]\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "process : [92/102]\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "process : [93/102]\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "process : [94/102]\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "process : [95/102]\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "process : [96/102]\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process : [97/102]\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "process : [98/102]\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "process : [99/102]\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "process : [100/102]\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "process : [101/102]\n",
      "(in func parllutils.batch_hessian) num_batch : 1, batch_size : 50000\n",
      "matrix shape torch.Size([784, 784]), type <class 'torch.Tensor'>\n",
      "memory matrix for MUter method using perturb samples to calculate\n",
      "saving matrix...\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "# total train data, batch_size=args.parllsize \n",
    "pass_loader = make_loader(train_data, batch_size=pass_batch)\n",
    "print(len(pass_loader)) # 共102个batches，每个batch_size=128\n",
    "\n",
    "# # calculate of partial_(wx@xx^{-1}@xw) by parll (set batch_size=args.parllsize(128) for acceleration)\n",
    "# # process : [x/102] 批处理，计算所有 train_data 的 partial_𝜹𝜹 hessian matrix\n",
    "# matrix = parll_calculate_memory_matrix(model, pass_loader, args, method='MUter')\n",
    "# store_memory_matrix(matrix, args, method='MUter')\n",
    "# del matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25616983",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading memory matrix : ../data/MemoryMatrix/dataset_binaryMnist_adv_PGD_model_logistic_method_MUter_sample_perturbed.pt\n",
      "matrix shape torch.Size([784, 784]), type <class 'torch.Tensor'>\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "matrix = load_memory_matrix(args, method='MUter').to(device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
